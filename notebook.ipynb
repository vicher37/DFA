{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0  values  length\n",
      "2730       orology     100       7\n",
      "4247      totalize     100       8\n",
      "3853     solarized     100       9\n",
      "3820     sirenized     100       9\n",
      "3543     resinized     100       9\n",
      "2948     pectizing     100       9\n",
      "2126     jasperize     100       9\n",
      "1910     hyalinize     100       9\n",
      "3969     suberized     100       9\n",
      "1681     granitize     100       9\n",
      "1294     ergotized     100       9\n",
      "149      aphetizes     100       9\n",
      "1821     hepatizes     100       9\n",
      "367      bushelers     100       9\n",
      "678      cretinize     100       9\n",
      "326     bimetalist     100      10\n",
      "331     biocenosis     100      10\n",
      "3735    seborrheas     100      10\n",
      "435     catharizes     100      10\n",
      "2882    paralogize     100      10\n",
      "2865    palletized     100      10\n",
      "2585    myxedema's     100      10\n",
      "2501    molochized     100      10\n",
      "2373    melanizing     100      10\n",
      "1154    ebionizing     100      10\n",
      "1826    herborized     100      10\n",
      "1817    hemostasia     100      10\n",
      "1438    fetichizes     100      10\n",
      "1343    ethicizing     100      10\n",
      "2004   ideologized     100      11\n",
      "805    definitized     100      11\n",
      "834    delocalizes     100      11\n",
      "904    derecognize     100      11\n",
      "784    deemphasize     100      11\n",
      "1126  dramatizable     100      12\n",
      "1843  hibernicized     100      12\n",
      "901   deracializes     100      12\n",
      "1206  encarnalized     100      12\n",
      "2366  medicalizing     100      12\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'vickyzhang'\n",
    "\n",
    "from pandas import read_csv\n",
    "def process():\n",
    "    \"\"\"\n",
    "        The main process. It reads in a txt file, assigns values to each word, and sorts it according to the value.\n",
    "    \"\"\"\n",
    "    words = read_csv('american-words.80', header=None)\n",
    "    def get_value(word):\n",
    "        \"\"\"\n",
    "            A sub-process run on each word. It gets the value of each letter, and add up the values for the whole word.\n",
    "        \"\"\"\n",
    "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        sum = 0\n",
    "        for letter in word:\n",
    "            letter_value = letters.find(letter)\n",
    "            if letter_value == -1:\n",
    "                letter_value = 0\n",
    "            sum += letter_value\n",
    "        return sum\n",
    "    words['values'] = words[0].apply(get_value)\n",
    "    # get those words whose values are 100\n",
    "    words = words[words['values'] == 100]\n",
    "    # get the length of these words and sort ascending\n",
    "    words['length'] = words[0].apply(len)\n",
    "    words = words.sort(columns='length')\n",
    "    return words\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(process())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
